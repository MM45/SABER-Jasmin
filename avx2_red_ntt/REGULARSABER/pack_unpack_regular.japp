








param int CRYPTO_SECRETKEYBYTES = 2304;
param int CRYPTO_PUBLICKEYBYTES = (3 * 320 + 32);
param int CRYPTO_BYTES = 32;
param int CRYPTO_CIPHERTEXTBYTES = 1088;
param int Saber_type = 2;

param int SABER_K = 3;
param int SABER_MU = 8;
param int SABER_ET = 4;

param int SABER_EQ = 13;
param int SABER_EP = 10;

param int SABER_N = 256;
param int SABER_Q = 8192;
param int SABER_P = 1024;

param int SABER_SEEDBYTES = 32;
param int SABER_NOISESEEDBYTES = 32;
param int SABER_COINBYTES = 32;
param int SABER_KEYBYTES = 32;

param int SABER_HASHBYTES = 32;

param int SABER_POLYBYTES = 416;

param int SABER_POLYVECBYTES = (SABER_K * SABER_POLYBYTES);

param int SABER_POLYVECCOMPRESSEDBYTES = (SABER_K * 320);

param int SABER_CIPHERTEXTBYTES = (SABER_POLYVECCOMPRESSEDBYTES);



param int SABER_SCALEBYTES_KEM = (SABER_ET * SABER_N / 8);

param int SABER_INDCPA_PUBLICKEYBYTES = (SABER_POLYVECCOMPRESSEDBYTES + SABER_SEEDBYTES);
param int SABER_INDCPA_SECRETKEYBYTES = (SABER_POLYVECBYTES);

param int SABER_PUBLICKEYBYTES = (SABER_INDCPA_PUBLICKEYBYTES);

param int SABER_SECRETKEYBYTES = (SABER_INDCPA_SECRETKEYBYTES + SABER_INDCPA_PUBLICKEYBYTES + SABER_HASHBYTES + SABER_KEYBYTES);

param int SABER_BYTES_CCA_DEC = (SABER_POLYVECCOMPRESSEDBYTES + SABER_SCALEBYTES_KEM);



param int SABER_KN = (SABER_K * SABER_N);
param int SABER_KKN = (SABER_K * SABER_K * SABER_N);
param int N_SB = (SABER_N / 4);
param int N_SB_RES = (2 * N_SB - 1);

param int SHAKE128_RATE = 168;
param int SHAKE256_RATE = 136;
param int SHA3_256_RATE = 136;
param int SHA3_512_RATE = 72;

param int KK13N8 = (SABER_K * SABER_K * (13 * SABER_N / 8));
param int MUNK8 = (SABER_MU * SABER_N * SABER_K / 8);

param int h1 = 4;
param int h2 = 228;




u128 zero_u128 = 0;

u256 zero_u256 = 0;

u256 h1_16u16 = 0x0004000400040004000400040004000400040004000400040004000400040004;
u256 h2_16u16 = 0x00e400e400e400e400e400e400e400e400e400e400e400e400e400e400e400e4;
u256 modp_16u16 = 0x03ff03ff03ff03ff03ff03ff03ff03ff03ff03ff03ff03ff03ff03ff03ff03ff;
u256 modq_16u16 = 0x1fff1fff1fff1fff1fff1fff1fff1fff1fff1fff1fff1fff1fff1fff1fff1fff;

u256 twobit_mask_16u16 = 0x0003000300030003000300030003000300030003000300030003000300030003;
u256 fourbit_mask_16u16 = 0x000f000f000f000f000f000f000f000f000f000f000f000f000f000f000f000f;
u256 sixbit_mask_16u16 = 0x003f003f003f003f003f003f003f003f003f003f003f003f003f003f003f003f;

u256 modq_8u32 = 0x00001fff00001fff00001fff00001fff00001fff00001fff00001fff00001fff;

u256 fourbit_mask_8u32 = 0x0000000f0000000f0000000f0000000f0000000f0000000f0000000f0000000f;
u256 sixteenbit_mask_8u32 = 0x0000ffff0000ffff0000ffff0000ffff0000ffff0000ffff0000ffff0000ffff;

u256 onebit_mask_64u4 = 0x1111111111111111111111111111111111111111111111111111111111111111;

u256 five_mask_64u4 = 0x5555555555555555555555555555555555555555555555555555555555555555;
u256 three_mask_64u4 = 0x3333333333333333333333333333333333333333333333333333333333333333;
u256 fourbit_mask_32u8 = 0x0f0f0f0f0f0f0f0f0f0f0f0f0f0f0f0f0f0f0f0f0f0f0f0f0f0f0f0f0f0f0f0f;






inline fn SABER_pack_4bit(reg ptr u8[SABER_SCALEBYTES_KEM] bytes, reg ptr u16[SABER_N] data) -> reg ptr u8[SABER_SCALEBYTES_KEM]
{
 inline int i;
 inline int j;

 reg u128[4] zero_offset128;
 reg u128[4] one_offset128;

 reg u256[2] zero_offset256;
 reg u256[2] one_offset256;
 reg u256[2] t256;
 reg u256 b256;
 reg u256 fourbit_mask;

 zero_offset128[0] = zero_u128;
 zero_offset128[1] = zero_u128;
 zero_offset128[2] = zero_u128;
 zero_offset128[3] = zero_u128;
 one_offset128[0] = zero_u128;
 one_offset128[1] = zero_u128;
 one_offset128[2] = zero_u128;
 one_offset128[3] = zero_u128;

 zero_offset256[0] = zero_u256;
 zero_offset256[1] = zero_u256;
 one_offset256[0] = zero_u256;
 one_offset256[1] = zero_u256;
 fourbit_mask = fourbit_mask_16u16;

 for i = 0 to SABER_N / 64 {
  for j = 0 to 8 {
   zero_offset128[0] = #VPINSR_16u16(zero_offset128[0], data[i * 64 + 2 * j], j);
   zero_offset128[1] = #VPINSR_16u16(zero_offset128[1], data[16 + i * 64 + 2 * j], j);
   zero_offset128[2] = #VPINSR_16u16(zero_offset128[2], data[32 + i * 64 + 2 * j], j);
   zero_offset128[3] = #VPINSR_16u16(zero_offset128[3], data[48 + i * 64 + 2 * j], j);
   one_offset128[0] = #VPINSR_16u16(one_offset128[0], data[1 + i * 64 + 2 * j], j);
   one_offset128[1] = #VPINSR_16u16(one_offset128[1], data[16 + 1 + i * 64 + 2 * j], j);
   one_offset128[2] = #VPINSR_16u16(one_offset128[2], data[32 + 1 + i * 64 + 2 * j], j);
   one_offset128[3] = #VPINSR_16u16(one_offset128[3], data[48 + 1 + i * 64 + 2 * j], j);
  }

  zero_offset256[0] = #VINSERTI128(zero_offset256[0], zero_offset128[0], 0);
  one_offset256[0] = #VINSERTI128(one_offset256[0], one_offset128[0], 0);
  zero_offset256[1] = #VINSERTI128(zero_offset256[1], zero_offset128[2], 0);
  one_offset256[1] = #VINSERTI128(one_offset256[1], one_offset128[2], 0);
  zero_offset256[0] = #VINSERTI128(zero_offset256[0], zero_offset128[1], 1);
  one_offset256[0] = #VINSERTI128(one_offset256[0], one_offset128[1], 1);
  zero_offset256[1] = #VINSERTI128(zero_offset256[1], zero_offset128[3], 1);
  one_offset256[1] = #VINSERTI128(one_offset256[1], one_offset128[3], 1);

  one_offset256[0] &= fourbit_mask;
  one_offset256[1] &= fourbit_mask;

  zero_offset256[0] &= fourbit_mask;
  zero_offset256[1] &= fourbit_mask;

  one_offset256[0] <<16u16= 4;
  one_offset256[1] <<16u16= 4;

  t256[0] = #VPACKUS_16u16(zero_offset256[0], zero_offset256[1]);
  t256[1] = #VPACKUS_16u16(one_offset256[0], one_offset256[1]);

  t256[0] = #VPERMQ(t256[0], 216);
  t256[1] = #VPERMQ(t256[1], 216);

  b256 = t256[0] | t256[1];

  bytes[u256 i] = b256;
 }

 return bytes;
}







inline fn SABER_un_pack4bit(reg ptr u8[SABER_SCALEBYTES_KEM] bytes, reg ptr u16[SABER_N] ar) -> reg ptr u16[SABER_N]
{
 inline int i;

 reg u128[2] b128;

 reg u256 fourbit_mask;
 reg u256[2] b256;
 reg u256[2] t256;
 reg u256[2] r256;

 fourbit_mask = fourbit_mask_16u16;

 for i = 0 to SABER_N / 32 {
  b128[0] = bytes[u128 i];
  b128[1] = bytes[u128 i];

  b256[0] = #VPMOVZX_16u8_16u16(b128[0]);
  b256[1] = #VPMOVZX_16u8_16u16(b128[1]);

  b256[0] &= fourbit_mask;
  b256[1] >>16u16= 4;

  t256[0] = #VPUNPCKL_16u16(b256[0], b256[1]);
  t256[1] = #VPUNPCKH_16u16(b256[0], b256[1]);

  r256[0] = #VPERM2I128(t256[0], t256[1], (8u1) [0, 0, 1, 0, 0, 0, 0, 0]);
  r256[1] = #VPERM2I128(t256[0], t256[1], (8u1) [0, 0, 1, 1, 0, 0, 0, 1]);

  ar[u256 2 * i] = r256[0];
  ar[u256 2 * i + 1] = r256[1];
 }

 return ar;
}







fn POLVECp2BS(reg ptr u8[SABER_POLYVECCOMPRESSEDBYTES] bytes, reg ptr u16[SABER_KN] data) -> reg ptr u8[SABER_POLYVECCOMPRESSEDBYTES]
{
 reg u32 d1;
 reg u32 d2;

 reg u64 address_bytes;
 reg u64 address_data;

 address_bytes = 0;
 address_data = 0;

 while (address_data < SABER_KN) {

  d1 = (32u) data[(int) address_data];
  bytes[(int) address_bytes] = (8u) d1;


  d1 = (32u) data[(int) address_data];
  d2 = (32u) data[(int) (address_data + 1)];
  d1 >>= 8;
  d2 <<= 2;
  d1 &= 0x03;
  d1 |= d2;
  bytes[(int) (address_bytes + 1)] = (8u) d1;


  d1 = (32u) data[(int) (address_data + 1)];
  d2 = (32u) data[(int) (address_data + 2)];
  d1 >>= 6;
  d2 <<= 4;
  d1 &= 0x0f;
  d1 |= d2;
  bytes[(int) (address_bytes + 2)] = (8u) d1;


  d1 = (32u) data[(int) (address_data + 2)];
  d2 = (32u) data[(int) (address_data + 3)];
  d1 >>= 4;
  d2 <<= 6;
  d1 &= 0x3f;
  d1 |= d2;
  bytes[(int) (address_bytes + 3)] = (8u) d1;


  d1 = (32u) data[(int) (address_data + 3)];
  d1 >>= 2;
  bytes[(int) (address_bytes + 4)] = (8u) d1;

  address_bytes += 5;
  address_data += 4;
 }

 return bytes;
}







inline fn POLVECq2BS(reg ptr u8[SABER_POLYVECBYTES] bytes, reg ptr u16[SABER_KN] data) -> reg ptr u8[SABER_POLYVECBYTES]
{
 reg u32 d1;
 reg u32 d2;

 reg u64 address_bytes;
 reg u64 address_data;

 address_bytes = 0;
 address_data = 0;

 while (address_data < SABER_KN) {

  d1 = (32u) data[(int) address_data];
  bytes[(int) address_bytes] = (8u) d1;


  d1 = (32u) data[(int) address_data];
  d2 = (32u) data[(int) (address_data + 1)];
  d1 >>= 8;
  d2 <<= 5;
  d1 &= 0x1f;
  d1 |= d2;
  bytes[(int) (address_bytes + 1)] = (8u) d1;


  d1 = (32u) data[(int) (address_data + 1)];
  d1 >>= 3;
  bytes[(int) (address_bytes + 2)] = (8u) d1;


  d1 = (32u) data[(int) (address_data + 1)];
  d2 = (32u) data[(int) (address_data + 2)];
  d1 >>= 11;
  d2 <<= 2;
  d1 &= 0x03;
  d1 |= d2;
  bytes[(int) (address_bytes + 3)] = (8u) d1;


  d1 = (32u) data[(int) (address_data + 2)];
  d2 = (32u) data[(int) (address_data + 3)];
  d1 >>= 6;
  d2 <<= 7;
  d1 &= 0x7f;
  d1 |= d2;
  bytes[(int) (address_bytes + 4)] = (8u) d1;


  d1 = (32u) data[(int) (address_data + 3)];
  d1 >>= 1;
  bytes[(int) (address_bytes + 5)] = (8u) d1;


  d1 = (32u) data[(int) (address_data + 3)];
  d2 = (32u) data[(int) (address_data + 4)];
  d1 >>= 9;
  d2 <<= 4;
  d1 &= 0x0f;
  d1 |= d2;
  bytes[(int) (address_bytes + 6)] = (8u) d1;


  d1 = (32u) data[(int) (address_data + 4)];
  d1 >>= 4;
  bytes[(int) (address_bytes + 7)] = (8u) d1;


  d1 = (32u) data[(int) (address_data + 4)];
  d2 = (32u) data[(int) (address_data + 5)];
  d1 >>= 12;
  d2 <<= 1;
  d1 &= 0x01;
  d1 |= d2;
  bytes[(int) (address_bytes + 8)] = (8u) d1;


  d1 = (32u) data[(int) (address_data + 5)];
  d2 = (32u) data[(int) (address_data + 6)];
  d1 >>= 7;
  d2 <<= 6;
  d1 &= 0x3f;
  d1 |= d2;
  bytes[(int) (address_bytes + 9)] = (8u) d1;


  d1 = (32u) data[(int) (address_data + 6)];
  d1 >>= 2;
  bytes[(int) (address_bytes + 10)] = (8u) d1;


  d1 = (32u) data[(int) (address_data + 6)];
  d2 = (32u) data[(int) (address_data + 7)];
  d1 >>= 10;
  d2 <<= 3;
  d1 &= 0x07;
  d1 |= d2;
  bytes[(int) (address_bytes + 11)] = (8u) d1;


  d1 = (32u) data[(int) (address_data + 7)];
  d1 >>= 5;
  bytes[(int) (address_bytes + 12)] = (8u) d1;

  address_data += 8;
  address_bytes += 13;
 }

 return bytes;
}







fn BS2POLVECp(reg ptr u8[SABER_POLYVECCOMPRESSEDBYTES] bytes, reg ptr u16[SABER_KN] data) -> reg ptr u16[SABER_KN]
{
 inline int i;
 inline int j;
 inline int k;

 reg u128 zero_offset128;
 reg u128 one_offset128;
 reg u128 two_offset128;
 reg u128 three_offset128;
 reg u128 four_offset128;

 reg u256 zero_offset256;
 reg u256[2] one_offset256;
 reg u256[2] two_offset256;
 reg u256[2] three_offset256;
 reg u256 four_offset256;
 reg u256[4] t256;
 reg u256[4] r;
 reg u256[4] ord_r;

 reg u256 twobit_mask;
 reg u256 fourbit_mask;
 reg u256 sixbit_mask;

 zero_offset128 = zero_u128;
 one_offset128 = zero_u128;
 two_offset128 = zero_u128;
 three_offset128 = zero_u128;
 four_offset128 = zero_u128;

 twobit_mask = twobit_mask_16u16;
 fourbit_mask = fourbit_mask_16u16;
 sixbit_mask = sixbit_mask_16u16;

 for i = 0 to SABER_K {
  for j = 0 to SABER_N / 64 {
   for k = 0 to 16 {
    zero_offset128 = #VPINSR_16u8(zero_offset128, bytes[i * (80 * SABER_N / 64) + j * 80 + 5 * k], k);
    one_offset128 = #VPINSR_16u8(one_offset128, bytes[i * (80 * SABER_N / 64) + j * 80 + 1 + 5 * k], k);
    two_offset128 = #VPINSR_16u8(two_offset128, bytes[i * (80 * SABER_N / 64) + j * 80 + 2 + 5 * k], k);
    three_offset128 = #VPINSR_16u8(three_offset128, bytes[i * (80 * SABER_N / 64) + j * 80 + 3 + 5 * k], k);
    four_offset128 = #VPINSR_16u8(four_offset128, bytes[i * (80 * SABER_N / 64) + j * 80 + 4 + 5 * k], k);
   }

   zero_offset256 = #VPMOVZX_16u8_16u16(zero_offset128);
   one_offset256[0] = #VPMOVZX_16u8_16u16(one_offset128);
   one_offset256[1] = #VPMOVZX_16u8_16u16(one_offset128);
   two_offset256[0] = #VPMOVZX_16u8_16u16(two_offset128);
   two_offset256[1] = #VPMOVZX_16u8_16u16(two_offset128);
   three_offset256[0] = #VPMOVZX_16u8_16u16(three_offset128);
   three_offset256[1] = #VPMOVZX_16u8_16u16(three_offset128);
   four_offset256 = #VPMOVZX_16u8_16u16(four_offset128);

   one_offset256[0] &= twobit_mask;
   two_offset256[0] &= fourbit_mask;
   three_offset256[0] &= sixbit_mask;

   one_offset256[1] >>16u16= 2;
   two_offset256[1] >>16u16= 4;
   three_offset256[1] >>16u16= 6;

   one_offset256[0] <<16u16= 8;
   two_offset256[0] <<16u16= 6;
   three_offset256[0] <<16u16= 4;
   four_offset256 <<16u16= 2;

   one_offset256[1] &= sixbit_mask;
   two_offset256[1] &= fourbit_mask;
   three_offset256[1] &= twobit_mask;

   t256[0] = zero_offset256 | one_offset256[0];
   t256[1] = one_offset256[1] | two_offset256[0];
   t256[2] = two_offset256[1] | three_offset256[0];
   t256[3] = three_offset256[1] | four_offset256;

   r[0] = #VPUNPCKL_16u16(t256[0], t256[2]);
   r[1] = #VPUNPCKL_16u16(t256[1], t256[3]);
   r[2] = #VPUNPCKH_16u16(t256[0], t256[2]);
   r[3] = #VPUNPCKH_16u16(t256[1], t256[3]);

   r[0] = #VPERMQ(r[0], 216);
   r[1] = #VPERMQ(r[1], 216);
   r[2] = #VPERMQ(r[2], 216);
   r[3] = #VPERMQ(r[3], 216);

   ord_r[0] = #VPUNPCKL_16u16(r[0], r[1]);
   ord_r[1] = #VPUNPCKL_16u16(r[2], r[3]);
   ord_r[2] = #VPUNPCKH_16u16(r[0], r[1]);
   ord_r[3] = #VPUNPCKH_16u16(r[2], r[3]);

   data[u256 (i * SABER_N + j * 64) / 16] = ord_r[0];
   data[u256 (i * SABER_N + j * 64) / 16 + 1] = ord_r[1];
   data[u256 (i * SABER_N + j * 64) / 16 + 2] = ord_r[2];
   data[u256 (i * SABER_N + j * 64) / 16 + 3] = ord_r[3];
  }
 }

 return data;
}







fn BS2POLVECq(reg ptr u8[SABER_POLYVECBYTES] bytes, reg ptr u16[SABER_KN] data) -> reg ptr u16[SABER_KN]
{
 reg u32 b1;
 reg u32 b2;
 reg u32 b3;

 reg u64 address_bytes;
 reg u64 address_data;

 address_bytes = 0;
 address_data = 0;

 while (address_data < SABER_KN) {

  b2 = (32u) bytes[(int) (address_bytes + 1)];
  b1 = (32u) bytes[(int) address_bytes];
  b2 <<= 8;
  b2 &= 0x1f00;
  b1 |= b2;
  data[(int) address_data] = (16u) b1;


  b1 = (32u) bytes[(int) (address_bytes + 1)];
  b2 = (32u) bytes[(int) (address_bytes + 2)];
  b1 >>= 5;
  b2 <<= 3;
  b1 |= b2;
  b3 = (32u) bytes[(int) (address_bytes + 3)];
  b3 <<= 11;
  b3 &= 0x1800;
  b1 |= b3;
  data[(int) (address_data + 1)] = (16u) b1;


  b2 = (32u) bytes[(int) (address_bytes + 4)];
  b1 = (32u) bytes[(int) (address_bytes + 3)];
  b2 <<= 6;
  b1 >>= 2;
  b2 &= 0x1fc0;
  b1 |= b2;
  data[(int) (address_data + 2)] = (16u) b1;


  b1 = (32u) bytes[(int) (address_bytes + 4)];
  b2 = (32u) bytes[(int) (address_bytes + 5)];
  b1 >>= 7;
  b2 += b2;
  b1 |= b2;
  b3 = (32u) bytes[(int) (address_bytes + 6)];
  b3 <<= 9;
  b3 &= 0x1e00;
  b1 |= b3;
  data[(int) (address_data + 3)] = (16u) b1;


  b1 = (32u) bytes[(int) (address_bytes + 6)];
  b2 = (32u) bytes[(int) (address_bytes + 7)];
  b1 >>= 4;
  b2 <<= 4;
  b1 |= b2;
  b3 = (32u) bytes[(int) (address_bytes + 8)];
  b3 <<= 12;
  b3 &= 0x1000;
  b1 |= b3;
  data[(int) (address_data + 4)] = (16u) b1;


  b2 = (32u) bytes[(int) (address_bytes + 9)];
  b1 = (32u) bytes[(int) (address_bytes + 8)];
  b2 <<= 7;
  b1 >>= 1;
  b2 &= 0x1f80;
  b1 |= b2;
  data[(int) (address_data + 5)] = (16u) b1;


  b1 = (32u) bytes[(int) (address_bytes + 9)];
  b2 = (32u) bytes[(int) (address_bytes + 10)];
  b1 >>= 6;
  b2 <<= 2;
  b1 |= b2;
  b3 = (32u) bytes[(int) (address_bytes + 11)];
  b3 <<= 10;
  b3 &= 0x1c00;
  b1 |= b3;
  data[(int) (address_data + 6)] = (16u) b1;


  b1 = (32u) bytes[(int) (address_bytes + 11)];
  b2 = (32u) bytes[(int) (address_bytes + 12)];
  b1 >>= 3;
  b2 <<= 5;
  b1 |= b2;
  data[(int) (address_data + 7)] = (16u) b1;

  address_data += 8;
  address_bytes += 13;
 }

 return data;
}

export fn SABER_pack_4bit_jazz(reg u64 bytesp, reg u64 datap)
{
 inline int i;

 reg u256 t256;

 stack u8[SABER_SCALEBYTES_KEM] bytes;
 stack u16[SABER_N] data;

 for i = 0 to SABER_N / 16 {
  t256 = (u256) [datap + 32 * i];
  data[u256 i] = t256;
 }

 bytes = SABER_pack_4bit(bytes, data);

 for i = 0 to SABER_SCALEBYTES_KEM / 32 {
  t256 = bytes[u256 i];
  (u256) [bytesp + 32 * i] = t256;
 }

}


export fn SABER_un_pack4bit_jazz(reg u64 bytesp, reg u64 datap)
{
 inline int i;

 reg u256 t256;

 stack u8[SABER_SCALEBYTES_KEM] bytes;
 stack u16[SABER_N] data;

 for i = 0 to SABER_SCALEBYTES_KEM / 32 {
  t256 = (u256) [bytesp + 32 * i];
  bytes[u256 i] = t256;
 }

 data = SABER_un_pack4bit(bytes, data);

 for i = 0 to SABER_N / 16 {
  t256 = data[u256 i];
  (u256) [datap + 32 * i] = t256;
 }

}

export fn POLVECp2BS_jazz(reg u64 bytesp, reg u64 datap)
{
 inline int i;

 reg u256 t256;

 stack u8[SABER_POLYVECCOMPRESSEDBYTES] bytes;
 stack u16[SABER_KN] data;

 for i = 0 to SABER_KN / 16 {
  t256 = (u256) [datap + 32 * i];
  data[u256 i] = t256;
 }

 bytes = POLVECp2BS(bytes, data);

 for i = 0 to SABER_POLYVECCOMPRESSEDBYTES / 32 {
  t256 = bytes[u256 i];
  (u256) [bytesp + 32 * i] = t256;
 }

}

export fn POLVECq2BS_jazz(reg u64 bytesp, reg u64 datap)
{
 inline int i;

 reg u256 t256;

 stack u8[SABER_POLYVECBYTES] bytes;
 stack u16[SABER_KN] data;

 for i = 0 to SABER_KN / 16 {
  t256 = (u256) [datap + 32 * i];
  data[u256 i] = t256;
 }

 bytes = POLVECq2BS(bytes, data);

 for i = 0 to SABER_POLYVECBYTES / 32 {
  t256 = bytes[u256 i];
  (u256) [bytesp + 32 * i] = t256;
 }
}

export fn BS2POLVECp_jazz(reg u64 bytesp, reg u64 datap)
{
 inline int i;

 reg u256 t256;

 stack u8[SABER_POLYVECCOMPRESSEDBYTES] bytes;
 stack u16[SABER_KN] data;


 for i = 0 to SABER_POLYVECCOMPRESSEDBYTES / 32 {
  t256 = (u256) [bytesp + 32 * i];
  bytes[u256 i] = t256;
 }

 data = BS2POLVECp(bytes, data);

 for i = 0 to SABER_KN / 16 {
  t256 = data[u256 i];
  (u256) [datap + 32 * i] = t256;
 }
}

export fn BS2POLVECq_jazz(reg u64 bytesp, reg u64 datap)
{
 inline int i;

 reg u256 t256;

 stack u8[SABER_POLYVECBYTES] bytes;
 stack u16[SABER_KN] data;

 for i = 0 to SABER_POLYVECBYTES / 32 {
  t256 = (u256) [bytesp + 32 * i];
  bytes[u256 i] = t256;
 }

 data = BS2POLVECq(bytes, data);

 for i = 0 to SABER_KN / 16 {
  t256 = data[u256 i];
  (u256) [datap + 32 * i] = t256;
 }
}
